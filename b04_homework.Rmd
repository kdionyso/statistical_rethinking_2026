---
title: "B04 Homework for Statistical Rethinking"
author: "Kyriaki Dionysopoulou"
date: "`r Sys.Date()`"
output: html_document
---

## Data
```{r echo=TRUE} 
# install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty", "shape"))
# install.packages("devtools")
# install.packages("knitr")
# devtools::install_github("rmcelreath/rethinking", force = TRUE)
# install.packages("RColorBrewer")
library(RColorBrewer)
library(rethinking)

data(bangladesh)
d <- bangladesh
str(d)

dat <- list(
    C = d$use.contraception,
    D = as.integer(d$district),
    U = as.integer(d$urban),
    A = standardize(d$age.centered),
    K = d$living.children, # use ordered data here
    alpha = rep(2, max(d$living.children) - 1),
    MAXK = max(d$living.children),
    MAXD = max(d$district)
)
```

## Original model

```{r}
mPPO <- ulam(
    alist(
        C ~ bernoulli(p),
        logit(p) <- a[D] +
            bK[D] *
                sum(delta_j[1:K]) +
            bA * A +
            bU[D] * U,
        bA ~ normal(0, 0.5),
        transpars > vector[MAXD]:a <<- abar[1] + v[, 1],
        transpars > vector[MAXD]:bK <<- abar[2] + v[, 2],
        transpars > vector[MAXD]:bU <<- abar[3] + v[, 3],
        transpars > matrix[MAXD, 3]:v <- compose_noncentered(sigma, L_Rho, Z),
        vector[3]:abar ~ normal(0, 1),
        matrix[3, MAXD]:Z ~ normal(0, 1),
        vector[3]:sigma ~ exponential(1),
        cholesky_factor_corr[3]:L_Rho ~ lkj_corr_cholesky(4),
        vector[MAXK]:delta_j <<- append_row(0, delta),
        simplex[MAXK - 1]:delta ~ dirichlet(alpha),
        gq > matrix[3, 3]:Rho <<- Chol_to_Corr(L_Rho)
    ),
    data = dat,
    chains = 4,
    cores = 4,
    cmdstan = TRUE,
    log_lik = TRUE
)
```

Now time to check the dashboard
```{r}
dashboard(mPPO)
```
and the stanfit object for divergences, or other warnings.
```{r}
mPPO@cstanfit$cmdstan_diagnose()
# precis(mPPO, depth = 2)
```
Diagnostics seem ok with no problems. Some variables with Rhat at about 1.01, but other than that all looks good.
```{r}
precis(mPPO, depth = 3, pars = "Rho")
```
Correlation between bK and bU is relatively weak. Adding A to the mix of correlated variables shows an even weaker correlation.

Let's have a look at the density profiles for each contraception group by age.

```{r echo=FALSE, out.width="50%", fig.cap="A nice image."}
par(mfrow = c(1, 1))
# devAskNewPage(ask = TRUE)
# display.brewer.all(type = "seq")

brewer.pal.info["YlOrRd", ]$maxcolors
pal <- brewer.pal(brewer.pal.info["YlOrRd", ]$maxcolors, "YlOrRd")

plot(NULL, xlim = c(-3, 3), ylim = c(0, 1), xlab = "A", ylab = "Density[A]")
# plot(dat$C ~ dat$A)
# for (i in unique(dat$D)) {
#     dens(dat$A[dat$D == i], col = pal[i], add = TRUE)
#     # lines(dens(dat$A[dat$D == i]))
# }
library(ggplot2)
# Basic violin plot
p <- ggplot(as.data.frame(list(C = as.factor(dat$C), D = as.factor(dat$D), A = dat$A)), aes(x = C, y = A)) +
    geom_violin(trim = FALSE)
p <- p + scale_x_discrete(limits = c("0", "1"))
p <- p + stat_summary(fun.y = mean, geom = "point", shape = 23, size = 2)
p <- p + geom_boxplot(width = 0.1)
# Rotate the violin plot
p <- p + stat_summary(fun.y = median, geom = "point", shape = 25, size = 4, col = 4)
p + coord_flip()
```
```{r}
postPPO <- extract.samples(mPPO)
```
## Fixed effects model with confounding variable
In the fixed effects model the intercept doesn't vary within the group. Non-centered parametrization introduces some multi-level element to the model which we don't necessarily need here.
```{r}
datFE <- list(
    C = d$use.contraception,
    D = as.integer(d$district),
    U = as.integer(d$urban),
    A = standardize(d$age.centered),
    K = d$living.children, # use ordered data here
    alpha = rep(2, max(d$living.children) - 1),
    MAXK = max(d$living.children),
    MAXD = max(d$district),
    Kbar = sapply(1:max(d$district), function(q) {
        return(
            if (length(d$living.children[d$district == q]) > 0) {
                return(
                    sum(d$living.children[d$district == q]) /
                        (sum(as.integer(d$district == q)) *
                            max(d$living.children))
                )
            } else {
                return(0)
            }
        )
    }),
    Ubar = sapply(1:max(d$district), function(q) {
        return(
            if (length(d$urban[d$district == q]) > 0) {
                return(mean(d$urban[d$district == q]))
            } else {
                return(0)
            }
        )
    })
)
mFE <- ulam(
    alist(
        C ~ bernoulli(p),
        logit(p) <- a[D] +
            bK *
                sum(delta_j[1:K]) - bK * Kbar[D] +
            bA * A +
            bU * U - bU * Ubar[D],
        vector[MAXD]:a ~ normal(0, 1),
        bA ~ normal(0, 0.5),
        bU ~ normal(0, 1),
        bK ~ normal(0, 1),
        vector[MAXK]:delta_j <<- append_row(0, delta),
        simplex[MAXK - 1]:delta ~ dirichlet(alpha)
    ),
    data = datFE,
    chains = 4,
    cores = 4,
    cmdstan = TRUE,
    log_lik = TRUE,
    sample = TRUE
)
# mFE_nc <- ulam(
#     alist(
#         C ~ bernoulli(p),
#         logit(p) <- (abar + z_a * sigma_a) +
#             (bkbar + z_bk * sigma_bk) *
#                 sum(delta_j[1:K]) -
#             (bkbar + z_bk * sigma_bk) * Kbar[D] +
#             bA * A +
#             (bubar + z_bu * sigma_bu) * U -
#             (bubar + z_bu * sigma_bu) * Ubar[D],
#         bA ~ normal(0, 0.5),
#         # a <- ,
#         # bK <- ,
#         # bU <- ,

#         abar ~ normal(0, 1),
#         bkbar ~ normal(0, 1),
#         bubar ~ normal(0, 1),
#         z_a ~ normal(0, 1),
#         z_bk ~ normal(0, 1),
#         z_bu ~ normal(0, 1),
#         c(sigma_a, sigma_bk, sigma_bu) ~ exponential(1),
#         vector[MAXK]:delta_j <<- append_row(0, delta),
#         simplex[MAXK - 1]:delta ~ dirichlet(alpha)
#     ),
#     data = datFE,
#     chains = 4,
#     cores = 4,
#     cmdstan = TRUE,
#     log_lik = TRUE
# )
```

Check the model through the dashboard and run cmdstan diagnostics. Some variables have $Rhat >1.01$ but everything looks good.

```{r out.width="50%", fig.cap="A nice image."}
dashboard(mFE)
```
```{r}
mFE@cstanfit$cmdstan_diagnose()
```

Check whether delta_j learnt anything meaningful
```{r}
precis(mFE, depth = 2, pars = "delta_j")
```
Check whether the parameters have learnt anything meaningful when compared to the prior. Original prior is shown with a dashed red line.
```{r}
par(mfrow = c(2, 1))
postMFE <- extract.samples(mFE)
plot(NULL, xlab = "a[D]", ylab = "Density", xlim = c(-3, 3), ylim = c(0, 1), cex = 4)
for (i in unique(dat$D)) {
    dens(postMFE$a[, i], add = TRUE, col = grau())
}
curve(dnorm(x, 0, 1), add = TRUE, lty = 2, col = "red", lw = 2)

dens(postMFE$bU, xlab = "bu/bK", col = "black")
dens(postMFE$bK, add = TRUE, col = 4, lw = 2)
curve(dnorm(x, 0, 1), add = TRUE, lty = 2, lw = 4, col = "red")
```
```{r}
compare(mPPO, mFE)
```
## Influence of surviving children on contraceptive use.
```{r}
apply(postMFE$bK, 2, mean)
```

```{r}
precis(mFE, depth = 3, pars = "bK")
```
We can't really compare those two parameters as they correspond to different effects, but just showing for the shake of it.
```{r}
precis(mPPO, depth = 3, pars = "bK")
```

Plot averages, etc...
```{r}
precis(mPPO, depth = 3, pars = "bK")
```

Plot predictions
```{r out.width="50%", fig.cap="Contraception proportion by district. Black dots correspond to real data and blue dots are the predictions."}
par(mfrow = c(1, 1))
plot(
    NULL,
    xlim = c(0, max(dat$D) * 0.2),
    ylim = c(0, 80),
    xlab = "district",
    ylab = "proportion[C]",
    main = "mFE",
    xaxt = "n"
)
res <- sapply(1:length(dat$D), function(q) {
    return(rbern(inv_logit(postMFE$p[, q])))
})

res_by_district <- sapply(1:max(dat$D), function(q) {
    apply(res[, which(dat$D == q)], 1, sum)
})

res_mean <- apply(res_by_district, 2, mean)
res_CI <- apply(res_by_district, 2, PI)

real_data <- sapply(1:max(dat$D), function(q) {
    sum(as.integer(dat$C[dat$D == q]))
})

axis(1, at = seq(from = 0.2, by = 0.2, length.out = max(dat$D)), labels = seq(from = 1, length.out = max(dat$D)))
for (i in 1:max(dat$D)) {
    lines(
        c(i * 0.2, i * 0.2),
        c(real_data[i], res_mean[i]),
        col = "black",
        lwd = 4,
        lt = 2
    )
    lines(
        c(i * 0.2, i * 0.2),
        c(res_CI[["5%", i]], res_CI[["94%", i]]),
        col = col.alpha(4, 0.4),
        lwd = 17,
        # cex=10,
        # pch=16
    )

    points(
        i * 0.2,
        real_data[i],
        col = "white",
        cex = 2,
        lwd = 4,
        pch = 16,
        bg = "white",
    )
    points(
        i * 0.2,
        real_data[i],
        col = "black",
        cex = 2,
        lwd = 4
    )

    points(
        i * 0.2,
        res_mean[i],
        col = "white",
        bg = "white",
        cex = 2,
        lwd = 4,
        pch = 16
    )
    points(
        i * 0.2,
        res_mean[i],
        col = 4,
        cex = 2,
        lwd = 4
    )
}
```
# Multi-level model with confounding variable


```{r}
datML <- list(
    C = d$use.contraception,
    D = as.integer(d$district),
    U = as.integer(d$urban),
    A = standardize(d$age.centered),
    K = d$living.children, # use ordered data here
    alpha = rep(2, max(d$living.children) - 1),
    MAXK = max(d$living.children),
    MAXD = max(d$district)
)
mML <- ulam(
    alist(
        C ~ bernoulli(p),
        logit(p) <- a[D] +
            bK[D] *
                sum(delta_j[1:K]) -
            bA * A +
            bU[D] * U,
        bA ~ normal(0, 0.5),
        transpars > vector[MAXD]:a <<- abar + z_a * sigma_a,
        transpars > vector[MAXD]:bK <<- bkbar + z_bk * sigma_bk,
        transpars > vector[MAXD]:bU <<- bubar + z_bu * sigma_bu,
        abar ~ normal(0, 1),
        bkbar ~ normal(0, 1),
        bubar ~ normal(0, 1),
        vector[MAXD]:z_a ~ normal(0, 1),
        vector[MAXD]:z_bk ~ normal(0, 1),
        vector[MAXD]:z_bu ~ normal(0, 1),
        c(sigma_a, sigma_bk, sigma_bu) ~ exponential(1),
        vector[MAXK]:delta_j <<- append_row(0, delta),
        simplex[MAXK - 1]:delta ~ dirichlet(alpha)
    ),
    data = dat,
    chains = 4,
    cores = 4,
    cmdstan = TRUE,
    log_lik = TRUE
)
```
Check model dashboard
```{r fig.cap = "mML model dashboard"}
dashboard(mML)
```
Cmdstan diagnostics
```{r}
mML@cstanfit$cmdstan_diagnose()
```
```{r}
# precis(mML, depth = 2)
precis(mML, depth = 2, pars = "delta_j")
```
Extract samples:
```{r}
postmML <- extract.samples(mML)
```
It seems like bK and a are correlated. So we might need to create a

```{r}
par(mfrow = c(1, 1))
plot(
    apply(postmML$bK, 2, mean),
    apply(postmML$a, 2, mean),
    col = 2,
    xlab = "bK[D]",
    ylab = "a[D]",
    cex = 2,
    lwd = 4
)
```

It seems like bK and a are correlated. So we might need to create a multi-level model with correlated features.Will try non-centered multilevel model

```{r}
mML_nc_pp_corr <- ulam(
    alist(
        C ~ bernoulli(p),
        logit(p) <- a[D] +
            bK[D] *
                sum(delta_j[1:K]) -
            bA * A +
            bU[D] * U,
        bA ~ normal(0, 0.5),
        transpars > vector[MAXD]:a <<- abar[1] + v[, 1],
        transpars > vector[MAXD]:bK <<- abar[2] + v[, 2],
        transpars > vector[MAXD]:bU <<- abar[3] + v[, 3],
        vector[3]:abar ~ normal(0, 1),
        transpars > matrix[MAXD, 3]:v <- compose_noncentered(sigma, L_Rho, Z),
        matrix[3, MAXD]:Z ~ normal(0, 1),
        vector[3]:sigma ~ exponential(1),
        cholesky_factor_corr[3]:L_Rho ~ lkj_corr_cholesky(4),
        vector[MAXK]:delta_j <<- append_row(0, delta),
        simplex[MAXK - 1]:delta ~ dirichlet(alpha),
        gq > matrix[3, 3]:Rho <<- Chol_to_Corr(L_Rho)
    ),
    data = dat,
    chains = 4,
    cores = 4,
    cmdstan = TRUE,
    log_lik = TRUE
)
```
Check model's dashboard and diagnostics
```{r}
dashboard(mML_nc_pp_corr)
```
The model is not particularly great as it has lots of variables with Rhat values above 1.01.
```{r}
mML_nc_pp_corr@cstanfit$cmdstan_diagnose()
```
```{r}
postmML_nc_pp_corr <- extract.samples(mML_nc_pp_corr)
```
Check correlations, idealy everything should be split by district (TODO!)
```{r}
par(mfrow = c(3, 1))
plot(
    apply(postmML_nc_pp_corr$bK, 2, mean),
    apply(postmML_nc_pp_corr$a, 2, mean),
    col = 2,
    xlab = "bK[D]",
    ylab = "a[D]",
    cex = 2,
    lwd = 4
)
plot(
    apply(postmML_nc_pp_corr$bU, 2, mean),
    apply(postmML_nc_pp_corr$a, 2, mean),
    col = 2,
    xlab = "bU[D]",
    ylab = "a[D]",
    cex = 2,
    lwd = 4
)

plot(
    apply(postmML_nc_pp_corr$bU, 2, mean),
    apply(postmML_nc_pp_corr$bK, 2, mean),
    col = 2,
    xlab = "bU[D]",
    ylab = "bK[D]",
    cex = 2,
    lwd = 4
)
```

# Mundlak model with confounding variable
# Trial
# Latent Mundlak model with confounding variable

```{r}
dat <- list(
    C = d$use.contraception,
    D = as.integer(d$district),
    U = as.integer(d$urban),
    A = standardize(d$age.centered),
    K = d$living.children, # use ordered data here
    alpha = rep(2, max(d$living.children) - 1),
    MAXK = max(d$living.children),
    MAXD = max(d$district)
)
mLMMCF <- ulam(
    alist(
        C ~ bernoulli(p),
        logit(p) <- a[D] +
            bA * A +
            bU * U +
            bK * sum(delta_j[1:K]) +
            bUG * UG[D],

        # parameters for top model
        transpars > vector[MAXD]:a <<- abar + z * tau,
        abar ~ normal(0, 1),
        vector[MAXD]:z ~ normal(0, 1),
        tau ~ exponential(1),
        bK ~ normal(0, 1),
        bA ~ normal(0, 0.5),
        bU ~ normal(0, 1),
        bUG ~ normal(0, 1),

        # U model
        U ~ bernoulli(pU),
        logit(pU) <- aU + bUD * UG[D],
        aU ~ normal(0, 1),
        bUD ~ exponential(1),

        # K model
        K ~ ordered_logistic(phi, cutpoints),
        phi <- aKK + bKK * UG[D],
        bKK ~ exponential(1),
        aKK ~ normal(0, 1),
        cutpoints ~ normal(0, 1),

        # UG model
        vector[MAXD]:UG ~ normal(0, 1),

        # the rest
        vector[MAXK]:delta_j <<- append_row(0, delta),
        simplex[MAXK - 1]:delta ~ dirichlet(alpha) # ,
        # # gq > matrix[2, 2]:Rho <<- Chol_to_Corr(L_Rho)
        # bK * sum(delta(1:K)) +
    ),
    data = dat,
    chains = 4,
    cores = 4,
    cmdstan = TRUE,
    log_lik = TRUE,
    sample = TRUE
)
precis(mLMMCF, depth = 3, pars = "delta_j")
```

Check model's dashboard
```{r}
dashboard(mLMMCF)
```
and diagnostics
```{r}
mLMMCF@cstanfit$cmdstan_diagnose()
```
Then extract samples to use for analysis later on.
```{r}
postLMMCF <- extract.samples(mLMMCF)
```
and compare with the rest of the models in terms of WAIC or PSIS (ideally psis).
```{r}
compare(mPPO, mFE, mML, mML_nc_pp_corr, mLMMCF)
```

### Plotting
Post check comparison among all models.
```{r echo=FALSE}
visualize_data <- function(post_model, model_label) {
    plot(
        NULL,
        xlim = c(0, max(dat$D) * 0.2),
        ylim = c(0, 80),
        xlab = "district",
        ylab = "proportion[C]",
        main = model_label,
        xaxt = "n"
    )

    res <- sapply(1:length(dat$D), function(q) {
        return(rbern(inv_logit(post_model$p[, q])))
    })

    res_by_district <- sapply(1:max(dat$D), function(q) {
        apply(res[, which(dat$D == q)], 1, sum)
    })

    res_mean <- apply(res_by_district, 2, mean)
    res_CI <- apply(res_by_district, 2, PI)
    str(res_CI)

    real_data <- sapply(1:max(dat$D), function(q) {
        sum(as.integer(dat$C[dat$D == q]))
    })

    axis(1, at = seq(from = 0.2, by = 0.2, length.out = max(dat$D)), labels = seq(from = 1, length.out = max(dat$D)))
    for (i in 1:max(dat$D)) {
        lines(
            c(i * 0.2, i * 0.2),
            c(real_data[i], res_mean[i]),
            col = "black",
            lwd = 4,
            lt = 2
        )
        lines(
            c(i * 0.2, i * 0.2),
            c(res_CI[["5%", i]], res_CI[["94%", i]]),
            col = col.alpha(4, 0.4),
            lwd = 17,
            # cex=10,
            # pch=16
        )

        points(
            i * 0.2,
            real_data[i],
            col = "white",
            cex = 2,
            lwd = 4,
            pch = 16,
            bg = "white",
        )
        points(
            i * 0.2,
            real_data[i],
            col = "black",
            cex = 2,
            lwd = 4
        )

        points(
            i * 0.2,
            res_mean[i],
            col = "white",
            bg = "white",
            cex = 2,
            lwd = 4,
            pch = 16
        )
        points(
            i * 0.2,
            res_mean[i],
            col = 4,
            cex = 2,
            lwd = 4
        )
    }
}
```
```{r out.height="50%", fig.cap="Contraception proportion by district. Black dots correspond to real data and blue dots are the predictions."}
par(mfrow = c(5, 1))
models <- list(mPPO = postPPO, mFE = postMFE, mML = postmML, mML_nc_corr = postmML_nc_pp_corr, LMMCF = postLMMCF)
for (mod in names(models)) {
    visualize_data(post_model = models[[mod]], model_label = mod)
}
```


```{r echo=FALSE}
visualize_data_proportions <- function(post_model, model_label) {
    plot(
        NULL,
        xlim = c(0, max(dat$D) * 0.2),
        ylim = c(0, 1),
        xlab = "district",
        ylab = "proportion[C]",
        main = model_label,
        xaxt = "n"
    )

    res <- sapply(1:length(dat$D), function(q) {
        return(rbern(inv_logit(post_model$p[, q])))
    })

    res_by_district <- sapply(1:max(dat$D), function(q) {
        apply(res[, which(dat$D == q)], 1, sum)
    })

    res_mean <- apply(res_by_district, 2, mean)
    res_CI <- apply(res_by_district, 2, PI)
    str(res_CI)

    real_data <- sapply(1:max(dat$D), function(q) {
        sum(as.integer(dat$C[dat$D == q]))
    })

    norms <- sapply(1:max(dat$D), function(q) {
        sum(as.integer(dat$D == q))
    })
    print(paste0(res_mean, norms))

    real_data_norm <- real_data / norms
    res_mean_norm <- res_mean / norms
    res_CI_norm <- res_CI / rbind(norms, norms)

    axis(1, at = seq(from = 0.2, by = 0.2, length.out = max(dat$D)), labels = seq(from = 1, length.out = max(dat$D)))
    for (i in 1:max(dat$D)) {
        lines(
            c(i * 0.2, i * 0.2),
            c(real_data_norm[i], res_mean_norm[i]),
            col = "black",
            lwd = 4,
            lt = 2
        )
        lines(
            c(i * 0.2, i * 0.2),
            c(res_CI_norm[["5%", i]], res_CI_norm[["94%", i]]),
            col = col.alpha(4, 0.4),
            lwd = 17,
            # cex=10,
            # pch=16
        )

        points(
            i * 0.2,
            real_data_norm[i],
            col = "white",
            cex = 2,
            lwd = 4,
            pch = 16,
            bg = "white",
        )
        points(
            i * 0.2,
            real_data_norm[i],
            col = "black",
            cex = 2,
            lwd = 4
        )

        points(
            i * 0.2,
            res_mean_norm[i],
            col = "white",
            bg = "white",
            cex = 2,
            lwd = 4,
            pch = 16
        )
        points(
            i * 0.2,
            res_mean_norm[i],
            col = 4,
            cex = 2,
            lwd = 4
        )
    }
}
```

```{r out.height="90%", fig.cap="Contraception proportion by district. Black dots correspond to real data and blue dots are the predictions."}
par(mfrow = c(5, 1))
models <- list(mPPO = postPPO, mFE = postMFE, mML = postmML, mML_nc_corr = postmML_nc_pp_corr, LMMCF = postLMMCF)
for (mod in names(models)) {
    visualize_data_proportions(post_model = models[[mod]], model_label = mod)
}
```
We see that all proportions are centered around 0.5, but that the spreads of the distributions for each one of the districts is different. The model appears to over-estimate the proportions in most cases, however for the majority of the cases the predictions are within the 89% confidence interval. __TODO: PLEASE CHECK__ 


# Examine effects of having several children on contraception
To examine the effects of having one child can be found by examining the posterior when $K=0$ and when $K=1$ and then ploting the density plot for $bK$ to identify the magnitude. For this we need a counter-factual simulation where for all records we place $K=0$, then repeat with $K=1$.

```{r}
dat_counter0 <- dat
dat_counter1 <- dat


postLMMCF <- extract.samples(mLMMCF)
par(mfrow = c(4, 1))
for (l in 0:3) {
    # dat_counter0$K <- rep(l, length(dat$K))
    # dat_counter1$K <- rep(l + 1, length(dat$K))
    # fake_list0 <- dat_counter0
    # fake_list1 <- dat_counter1

    fake_list0 <- list(D = 1:max(dat$D), K = rep(l, max(dat$D)), alpha = rep(2, max(d$living.children)), MAXK = max(d$living.children), MAXD = max(dat$D))
    fake_list1 <- list(D = 1:max(dat$D), K = rep(l + 1, max(dat$D)), alpha = rep(2, max(d$living.children)), MAXK = max(d$living.children), MAXD = max(dat$D))


    p0 <- sapply(1:length(fake_list0$K), function(i) {
        inv_logit(
            postLMMCF$a[, fake_list0$D[i]] +
                # bA * fake_list0$A +
                # bU * U +
                postLMMCF$bK * sum(postLMMCF$delta_j[, 1:fake_list0$K[i]])
            # bUG * UG[fake_list0$D]))
        )
    })

    p1 <- sapply(1:length(fake_list1$K), function(i) {
        inv_logit(
            postLMMCF$a[, fake_list1$D[i]] +
                # bA * fake_list0$A +
                # bU * U +
                postLMMCF$bK * sum(postLMMCF$delta_j[, 1:fake_list1$K[i]])
            # bUG * UG[fake_list0$D]))
        )
    })


    print(apply(p0 - p1, 2, mean))

    plot(NULL, xlim = c(-1.5, 1), ylim = c(0, 20), xlab = "p[C]", ylab = "Density", main = paste0("Difference between ", l, " and ", l + 1, "kids."))
    for (i in 1:max(dat$D)) {
        dens(p0[, i] - p1[, i], add = TRUE, col = col.alpha("black", i / max(dat$D)), lw = 4)
    }
}
```

```{r out.height="90%", fig.cap="Contraception proportion by district. Black dots correspond to real data and blue dots are the predictions."}
par(mfrow = c(5, 1))
models <- list(mPPO = postPPO, mFE = postMFE, mML = postmML, mML_nc_corr = postmML_nc_pp_corr, LMMCF = postLMMCF)
for (mod in names(models)) {
    visualize_data_proportions(post_model = models[[mod]], model_label = mod)
}
```

plot(
    NULL,
    xlim = c(0, max(dat$D) * 0.1),
    ylim = c(0, 1),
    xlab = "district",
    ylab = "proportion[C]",
    main = "mFE"
)
res <- rbern(
    1:length(dat$D),
    prob = apply(inv_logit(postMFE$p), 2, mean)
)
prop_pred <- sapply(1:max(dat$D), function(q) {
    return(sum(res[dat$D == q]) / sum(as.integer(dat$D == q)))
})
prop <- sapply(1:max(dat$D), function(q) {
    return(sum(dat$C[dat$D == q]) / sum(as.integer(dat$D == q)))
})
for (i in 1:length(dat$D)) {
    points(
        i * 0.1,
        prop[i],
        col = "black",
        cex = 2,
        lwd = 4
    )
    points(
        i * 0.1,
        prop_pred[i],
        col = 4,
        cex = 2,
        lwd = 4
    )
    lines(
        c(i * 0.1, i * 0.1),
        c(prop[i], prop_pred[i]),
        col = 4,
        lwd = 4,
        lt = 2
    )
}

plot(
    NULL,
    xlim = c(0, max(dat$D) * 0.1),
    ylim = c(0, 1),
    xlab = "district",
    ylab = "proportion[C]",
    main = "mML"
)
res <- rbern(
    1:length(dat$D),
    prob = apply(inv_logit(postmML$p), 2, mean)
)
prop_pred <- sapply(1:max(dat$D), function(q) {
    return(sum(res[dat$D == q]) / sum(as.integer(dat$D == q)))
})
prop <- sapply(1:max(dat$D), function(q) {
    return(sum(dat$C[dat$D == q]) / sum(as.integer(dat$D == q)))
})
for (i in 1:length(dat$D)) {
    points(
        i * 0.1,
        prop[i],
        col = "black",
        cex = 2,
        lwd = 4
    )
    points(
        i * 0.1,
        prop_pred[i],
        col = 4,
        cex = 2,
        lwd = 4
    )
    lines(
        c(i * 0.1, i * 0.1),
        c(prop[i], prop_pred[i]),
        col = 4,
        lwd = 4,
        lt = 2
    )
}


plot(
    NULL,
    xlim = c(0, max(dat$D) * 0.1),
    ylim = c(0, 1),
    xlab = "district",
    ylab = "proportion[C]",
    main = "ML_nc_pp_corr"
)
res <- rbern(
    1:length(dat$D),
    prob = apply(inv_logit(postmML_nc_pp_corr$p), 2, mean)
)
prop_pred <- sapply(1:max(dat$D), function(q) {
    return(sum(res[dat$D == q]) / sum(as.integer(dat$D == q)))
})
prop <- sapply(1:max(dat$D), function(q) {
    return(sum(dat$C[dat$D == q]) / sum(as.integer(dat$D == q)))
})
for (i in 1:length(dat$D)) {
    points(
        i * 0.1,
        prop[i],
        col = "black",
        cex = 2,
        lwd = 4
    )
    points(
        i * 0.1,
        prop_pred[i],
        col = 4,
        cex = 2,
        lwd = 4
    )
    lines(
        c(i * 0.1, i * 0.1),
        c(prop[i], prop_pred[i]),
        col = 4,
        lwd = 4,
        lt = 2
    )
}


plot(
    NULL,
    xlim = c(0, max(dat$D) * 0.1),
    ylim = c(0, 1),
    xlab = "district",
    ylab = "proportion[C]",
    main = "mLMMCF"
)
res <- rbern(
    1:length(dat$D),
    prob = apply(inv_logit(postLMMCF$p), 2, mean)
)
prop_pred <- sapply(1:max(dat$D), function(q) {
    return(sum(res[dat$D == q]) / sum(as.integer(dat$D == q)))
})
prop <- sapply(1:max(dat$D), function(q) {
    return(sum(dat$C[dat$D == q]) / sum(as.integer(dat$D == q)))
})
for (i in 1:length(dat$D)) {
    points(
        i * 0.1,
        prop[i],
        col = "black",
        cex = 2,
        lwd = 4
    )
    points(
        i * 0.1,
        prop_pred[i],
        col = 4,
        cex = 2,
        lwd = 4
    )
    lines(
        c(i * 0.1, i * 0.1),
        c(prop[i], prop_pred[i]),
        col = 4,
        lwd = 4,
        lt = 2
    )
} -->
```{r}
compare(mPPO, mFE, mML, mML_nc_pp_corr, mLMMCF)

mPPO@cstanfit$cmdstan_diagnose() # chains ok # TODO: some issues with parameters
kap <- as.data.frame(precis(mPPO, depth = 3))
lkap <- kap[
    ,
    grepl("rhat", colnames(kap)) |
        grepl("", colnames(kap)) |
        grepl("ess_bulk", colnames(kap))
]
lkap[(lkap$rhat > 1.01) | (lkap$ess_bulk < 200), ]
mFE@cstanfit$cmdstan_diagnose() # chains have divergences 0.2%
kap <- as.data.frame(precis(mFE, depth = 3))
lkap <- kap[
    ,
    grepl("rhat", colnames(kap)) |
        grepl("", colnames(kap)) |
        grepl("ess_bulk", colnames(kap))
]
lkap[(lkap$rhat > 1.01) | (lkap$ess_bulk < 200), ]
mML@cstanfit$cmdstan_diagnose() # chains ok, sigma_bu rhat ~=1.014
kap <- as.data.frame(precis(mML, depth = 3))
lkap <- kap[
    ,
    grepl("rhat", colnames(kap)) |
        grepl("", colnames(kap)) |
        grepl("ess_bulk", colnames(kap))
]
lkap[(lkap$rhat > 1.01) | (lkap$ess_bulk < 200), ]
mML_nc_pp_corr@cstanfit$cmdstan_diagnose() # chains with 1.02>rhat>1.01 # sigma[2], bK[7], v[30,2] # TODO: Something weird with parameters
kap <- as.data.frame(precis(mML_nc_pp_corr, depth = 3))
lkap <- kap[
    ,
    grepl("rhat", colnames(kap)) |
        grepl("", colnames(kap)) |
        grepl("ess_bulk", colnames(kap))
]
lkap[(lkap$rhat > 1.01) | (lkap$ess_bulk < 200), ]
mLMMCF@cstanfit$cmdstan_diagnose() # # chains with 1.02>rhat>1.01 aU
kap <- as.data.frame(precis(mLMMCF, depth = 3))
lkap <- kap[
    ,
    grepl("rhat", colnames(kap)) |
        grepl("", colnames(kap)) |
        grepl("ess_bulk", colnames(kap))
]
lkap[(lkap$rhat > 1.01) | (lkap$ess_bulk < 200), ]
```

